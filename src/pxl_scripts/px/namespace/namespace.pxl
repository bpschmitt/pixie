# Copyright 2018- The Pixie Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# SPDX-License-Identifier: Apache-2.0

''' Namespace Overview

This view gives a top-level summary of the pods and services in a given namespace,
as well as a service map.

'''
import px


# Flag to filter out requests that come from an unresolvable IP.
filter_unresolved_inbound = True
ns_per_ms = 1000 * 1000
ns_per_s = 1000 * ns_per_ms
# Window size to use on time_ column for bucketing.
window_ns = px.DurationNanos(10 * ns_per_s)

# ----------------------------------------------------------------
# Visualization Variables - No need to edit for basic configuration.
# ----------------------------------------------------------------
# K8s object is the abstraction to group on.
# Options are ['pod', 'service'].
k8s_object = 'service'
# Flag to filter out requests that come from an unresolvable IP.
filter_unresolved_inbound = True
# Flag to filter out health checks from the data.
filter_health_checks = True
# Flag to filter out ready checks from the data.
filter_ready_checks = True
# Flag to filter out non_k8s_traffic from the data.
filter_non_k8s_traffic = True
###############################

# ----------------------------------------------------------------
# Utility functions:
#
# These are shared functions. We plan to support imports in v0.3,
# which will allow these functions to be shared across multiple
# scripts.
# ----------------------------------------------------------------
def make_http_table(start_time: str):
    """ Makes the HTTP table given the passed in start.

    The data necessary to compute HTTP level svc information is located in the
    http_events table. We filter and aggregate data from this table to compute the
    required metrics.

    Args:
    @start_time The timestamp of data to start at.

    Returns: DataFrame of HTTP events with formatted columns.
    """
    df = px.DataFrame(table='http_events', start_time=start_time)
    df = format_http_table(df, filter_health_checks,
                           filter_ready_checks, filter_unresolved_inbound)
    return df

def format_http_table(df, filter_health_checks, filter_ready_checks,
                      filter_unresolved_inbound):
    """ Formats HTTP events tables

    Runs events table universal formatting, adds a response_size,
    creates a failure field marking which requests receive an error
    status code, and optionally filters out system monitoring requests
    and partial data points.

    Args:
    @df: the input http_events table.
    @filter_health_checks: flag to filter health checks.
    @filter_ready_checks: flag to filter health checks.
    @filter_unresolved_inbound: flag to filter unresolved inbound
        requests.

    Returns: formatted HTTP events DataFrame.
    """
    df = format_events_table(df, 'latency')
    df.resp_size = px.Bytes(px.length(df.resp_body))
    df.failure = df.resp_status >= 400
    df.pod = df.ctx['pod']
    df.namespace = df.ctx['namespace']
    df.svc = df.ctx['service']
    filter_out_conds = ((df.req_path != '/health' or not filter_health_checks) and (
        df.req_path != '/readyz' or not filter_ready_checks)) and (
        df['remote_addr'] != '-' or not filter_unresolved_inbound)

    df = df[filter_out_conds]
    return df


def format_events_table(df, latency_col):
    """ Format data and add semantic columns in event tables

    Unifies latency column to 'latency', adds a binned
    timestamp field to aggregate on, and adds the svc
    (k8s_object) as a semantic column.

    Works on "mysql_events" and "http_events"

    Args:
    @df: the input events table
    @latency_col: the name of the latency column in @df.

    Returns: formatted events DataFrame
    """
    df.latency = df[latency_col]

    df.timestamp = px.bin(df.time_, window_ns)
    df[k8s_object] = df.ctx[k8s_object]
    df = df[df[k8s_object] != '']
    return df

def http_code_table(start_time: str, namespace: px.Namespace):
    """ Builds a table of HTTP status codes grouped by Service

    Args:
    @start_time The timestamp of data to start at.
    @namespace: the name of the namespace.

    Returns: 
    DataFrame of the HTTP status code stats for inbound_service_let_summary
    in the selected @namespace.
    """
    df = make_http_table(start_time)
    matching_df = df[px.contains(df[k8s_object], namespace)]
    return matching_df.groupby(['svc','resp_status']).agg(count=('latency', px.count))

def pods_for_namespace(start_time: str, namespace: px.Namespace):
    ''' Gets a list of pods running per node.

    Args:
    @start_time Starting time of the data to examine.
    @namespace: The namespace to filter on.
    '''
    df = px.DataFrame(table='process_stats', start_time=start_time)
    df = df[df.ctx['namespace'] == namespace]
    df.pod = df.ctx['pod_name']
    df = df.groupby(['pod']).agg(
        rss=('rss_bytes', px.mean),
        vsize=('vsize_bytes', px.mean),
    )

    df.create_time = px.pod_name_to_start_time(df.pod)
    df.status = px.pod_name_to_status(df.pod)
    return df


def inbound_service_let_summary(start_time: str, namespace: px.Namespace):
    ''' Compute a summary of traffic by requesting service, for requests on services in `namespace`.

    Args:
    @start_time: The timestamp of data to start at.
    @namespace: The namespace to filter on.

    '''
    df = inbound_service_let_helper(start_time, namespace)

    per_ns_df = df.groupby(['timestamp', 'service']).agg(
        throughput_total=('latency', px.count),
        inbound_bytes_total=('req_size', px.sum),
        outbound_bytes_total=('resp_size', px.sum)
    )

    per_ns_df.request_throughput = per_ns_df.throughput_total / window_ns
    per_ns_df.inbound_throughput = per_ns_df.inbound_bytes_total / window_ns
    per_ns_df.outbound_throughput = per_ns_df.outbound_bytes_total / window_ns

    per_ns_df = per_ns_df.groupby(['service']).agg(
        request_throughput=('request_throughput', px.mean),
        inbound_throughput=('inbound_throughput', px.mean),
        outbound_throughput=('outbound_throughput', px.mean)
    )

    quantiles_df = df.groupby(['service']).agg(
        latency=('latency', px.quantiles),
        error_rate=('failure', px.mean)
    )
    quantiles_df.error_rate = px.Percent(quantiles_df.error_rate)

    joined = per_ns_df.merge(quantiles_df, left_on='service', right_on='service', how='inner',
                             suffixes=['', '_x'])
    return joined[['service', 'latency', 'request_throughput', 'error_rate',
                   'inbound_throughput', 'outbound_throughput']]


def inbound_service_let_graph(start_time: str, namespace: px.Namespace):
    ''' Compute a summary of traffic by requesting service, for requests on services in `namespace`.
        Similar to `inbound_let_summary` but also breaks down by pod in addition to service.

    Args:
    @start_time: The timestamp of data to start at.
    @namespace: The namespace to filter on.

    '''
    df = inbound_service_let_helper(start_time, namespace)

    df = df.groupby(['timestamp', 'service', 'remote_addr', 'pod']).agg(
        latency_quantiles=('latency', px.quantiles),
        error_rate=('failure', px.mean),
        throughput_total=('latency', px.count),
        inbound_bytes_total=('req_size', px.sum),
        outbound_bytes_total=('resp_size', px.sum)
    )

    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))
    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))
    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))

    df = df[df.remote_addr != '']
    df.responder_pod = df.pod
    df.requestor_pod_id = px.ip_to_pod_id(df.remote_addr)
    df.requestor_pod = px.pod_id_to_pod_name(df.requestor_pod_id)
    df.responder_service = df.service
    df.requestor_service = px.pod_id_to_service_name(df.requestor_pod_id)

    df.request_throughput = df.throughput_total / window_ns
    df.inbound_throughput = df.inbound_bytes_total / window_ns
    df.outbound_throughput = df.outbound_bytes_total / window_ns
    df.error_rate = px.Percent(df.error_rate)

    return df.groupby(['responder_pod', 'requestor_pod', 'responder_service',
                       'requestor_service']).agg(
        latency_p50=('latency_p50', px.mean),
        latency_p90=('latency_p90', px.mean),
        latency_p99=('latency_p99', px.mean),
        request_throughput=('request_throughput', px.mean),
        error_rate=('error_rate', px.mean),
        inbound_throughput=('inbound_throughput', px.mean),
        outbound_throughput=('outbound_throughput', px.mean),
        throughput_total=('throughput_total', px.sum)
    )


def inbound_service_let_helper(start_time: str, namespace: px.Namespace):
    ''' Compute the let as a timeseries for requests received or by services in `namespace`.

    Args:
    @start_time: The timestamp of data to start at.
    @namespace: The namespace to filter on.

    '''
    df = px.DataFrame(table='http_events', start_time=start_time)
    df.service = df.ctx['service']
    df.pod = df.ctx['pod_name']
    df = df[df.ctx['namespace'] == namespace and df.service != '']
    df.latency = df.latency

    df.timestamp = px.bin(df.time_, window_ns)

    df.req_size = px.Bytes(px.length(df.req_body))
    df.resp_size = px.Bytes(px.length(df.resp_body))
    df.failure = df.resp_status >= 400
    filter_out_conds = ((df.req_path != '/health' or not filter_health_checks) and (
        df.req_path != '/readyz' or not filter_ready_checks)) and (
        df['remote_addr'] != '-' or not filter_unresolved_inbound)

    df = df[filter_out_conds]
    return df
